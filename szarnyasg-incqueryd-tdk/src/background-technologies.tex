\chapter{Background technologies}
\label{chap:background-technologies}

Implementing a scalable graph pattern matcher requires a wide range of technologies. Careful selection of the technologies is critical to the project's success. For \iqd{}, we looked for technologies that can form the building blocks of a distributed, scalable model repository and pattern matcher. These technologies must been designed with scalability in mind and deployed at scale successfully. To avoid licensing issues, our search criteria included that, if possible, the technologies should be free and open-source solutions.

Usually, instance models are graph-like data structures. Therefore, we looked for scalable graph databases. In this context, scalability requires distributed storage and querying capabilities.

During the early phase of the research, we studied the architecture and limitations of the candidate systems. For databases, we inspected the data sharding strategies, consistency guarantees and transaction capabilities, along with the API and query methods. We also checked the systems' support for asynchronous processing, notification and messaging mechanisms.

In this chapter, we introduce the technologies that can form the basis of a scalable, distributed, asynchronous system. We also present EMF (Eclipse Modeling Framework), and \eiq{}, an incremental model query evaluation tool.

\section{Big Data and the NoSQL movement}

Since the 1980s, database management systems based on the relational data model~\cite{Codd:1970:RMD:362384.362685} dominated the database market. Relational databases have a number of important advantages: precise mathematical background, understandibility, mature tooling and so on. However, due to their rich feature set and the strongly connected nature of their data model, relational databases often have scalability issues~\cite{Jacobs:2009:PBD:1536616.1536632, Sakr13}. In practice, this renders them impractical for a number of use cases, e.g.\ running complex queries on large data sets.

In the last decade, large organizations struggled to store and process the huge amounts of data they produced. This problem introduces a diverse palette of scientific and engineering challenges, called \emph{Big Data} challenges. 

Big Data challenges spawned dozens of new database management systems. Typically, these systems broke with the strictness of the relational data model and utilized simpler, more scalable data models. These systems dropped support for the SQL query language used in relational databases and hence were called \emph{NoSQL databases}\footnote{The community now mostly interprets NoSQL as ''not only SQL''.}~\cite{NoSQL}. During the development of \iqd's propotype, we experimented with numerous NoSQL databases.

\section{Graph models and storage methods}

The graph is a well-known mathematical concept widely used in computer science. For our work, it is important to distinguish between different graph data models.

\myFigure{graph-classes}{Different graph data models~(based on \cite{DBLP:journals/corr/abs-1006-2361})}

The most basic graph model is the \emph{simple graph}, formally defined as $G = (V, E)$, where $V$ is the set of vertices and $E \subseteq V \times V$ is the set of edges. Simple graphs are sometimes referred as textbook-style graphs because they are an integral part of academic literature. Simple graphs are useful for modeling homogeneous systems and have plenty of algorithms for processing.

Simple graphs can be extended in several different ways (\figref{graph-classes}). To describe the connections in more detail, we may add directionality to edges (\emph{directed graph}), allow loops and multiple edges (\emph{multi-graph}). To allow different connections, we may label the edges (\emph{labeled graph}). \emph{RDF graph}s use URIs (Uniform Resource Identifiers) instead of labels, otherwise they have similar expressive power as labeled graphs. \emph{Property graph}s add even more possibilites by introducing properties. Each graph element, both vertices and edges can be described with a collection of properties. The properties are key--value pairs, e.g. \texttt{type = 'Person'}, \texttt{name = 'John'}, \texttt{age = 34}. 
Property graphs are powerful enough to describe Java objects or EMF instance models (\autoref{subsec:EMF}). 

\subsection{TinkerPop}

The \textit{TinkerPop} framework is an open-source software stack for graph storage and processing \cite{TinkerPop}. TinkerPop includes \textit{Blueprints}, a property graph model interface. Blueprints fulfills the same role for graph databases as JDBC does for relational databases. Most NoSQL graph databases implement the property graph interface provided by Blueprints, including Neo4j (\autoref{subsec:neo4j}), Titan (\autoref{subsec:titan}), DEX~\cite{DEX}, InfiniteGraph~\cite{InfiniteGraph} and OrientDB~\cite{OrientDB}.

\myFigureSmall{tinkerpop-stack}{The TinkerPop software stack \cite{Blueprints}}
 
TinkerPop also introduces a graph query language, \textit{Gremlin}. Gremlin is a domain-specific language based on Groovy, a Java-like dynamic language which runs on the Java Virtual Machine. Unlike most query languages, Gremlin is an imperative language with a strong focus on graph traversals. For example, if John's father is Jack and Jack's father is Scott, we may run the traversals shown on \lstref{gremlin-queries}.

\begin{lstlisting}[caption=Simple Gremlin queries, label=lst:gremlin-queries]
gremlin> g.V('name', 'John').out('father')
==>Jack
gremlin> g.V('name', 'John').out('father').out('father')
==>Scott
\end{lstlisting}

%\myFigureSideScalable{gremlin-example-graph}

Gremlin is based on \textit{Pipes}, TinkerPop's dataflow processing framework. Besides traversing, Gremlin is capable of analyzing and manipulating the graph as well.

TinkerPop also provides a graph server (\textit{Rexster}), a set of graph algorithms tailored for property graphs (\textit{Furnace}) and an object-graph mapper (\textit{Frames}). The TinkerPop software stack is shown on \figref{tinkerpop-stack}.


\subsection{Triplestores}

\textit{Triplestores} are tailored to store and process triples efficiently. A triple is a data entity composed of a subject, a predicate and an object, e.g.\ ''John instanceof Person'', ''John is 34''. Triplestores are mostly used in semantic technology projects. Also, some triplestores are capable of \emph{reasoning}, i.e.\ inferring logical consequences from a set of facts or axioms. 

Triplestores use the RDF (Resource Description Framework) data model. Although the RDF data model has less expressive power than the property graph data model, by introducing additional resources for each property, a property graph can be easily mapped to a RDF. Triplestores are usually queried via the RDF format's query language, SPARQL (recursive acronym for SPARQL Protocol and RDF Query Language). 

\section{NoSQL technologies}

In the following section we summarize the core technologies used in \iqd's prototype implementation. We briefly introduce the goals of each technology, with particular emphasis on the scalability aspects.
 
\subsection{Cassandra}

Cassandra is one of the most widely used NoSQL databases~\cite{Cassandra}. Originally developed by Facebook~\cite{Lakshman:2010:CDS:1773912.1773922}, Cassandra is now an open-source Apache project. The whole project is written in Java.

Cassandra's data model is called \emph{column family}. A column family is similar to a table of a relational database: it consists of rows and columns. However, unlike in a relational database's table, the rows do not have to have the same fixed set of columns. Instead, each row can have a different set of columns. This makes the data structure more dynamic and avoids the problems associated with NULL values.

Cassandra has sophisticated fault-tolerance mechanisms. It allows the application to balance between availability and consistency by allowing it to tune the consistency constraints.

Cassandra is used mainly by web 2.0 companies, including Digg, Netflix, Reddit, SoundCloud and Twitter. It is also used for research purposes at CERN and NASA \cite{CassandraCompanies}.

\subsubsection{Consistent hashing}

To distribute the data across the cluster, Cassandra uses a partitioner mechanism. The basic partitioners distribute the rows evenly based on their key's hash value. In a cluster with $n$ nodes, the na\"ive method for determining the location for a row with key $x$ is computing $ h(x) \bmod n $, where $h(x)$ is the hash function. Currently, Cassandra provides partitioners based on the MD5 and the Murmur3 hash function. However, this approach has a serious limitation: if we remove or add nodes to the cluster, we have to recompute the hash values and possibly relocate almost all rows in the cluster. To avoid this, Cassandra uses a special kind of hashing called \textit{consistent hashing}.

The ring is divided into ranges equal to the number of nodes, with each node being responsible for one or more ranges of the data. Before a node can join the ring, it must be assigned a \textit{token}. The token value determines the node's position in the ring and its range of data. The ring is walked clockwise until it locates the node with a token value greater than that of the row key. %Each node is responsible for the region of the ring between itself (inclusive) and its predecessor (exclusive). 
With the nodes sorted in token order, the last node is considered the predecessor of the first node; hence the ring representation\footnote{Note ''consistent'' here is different from both the idea of consistency in data consistency and in the ACID (atomicity, consistency, isolation, durability) properties guaranteed by transactions. It refers to the fact that tries to map the same rows to the same machine, even if the number of machines ($n$) changes over time slightly.} \cite{CassandraPartitioning}.

For example, consider a simple four-node cluster (\figref{cassandra-ring-partitions}), where all of the row keys managed by the cluster are in the range of 0 to 100. Each node is assigned a token that represents a point in this range. In this example, the token values are 0, 25, 50 and 75. The first node (with token 0), is responsible for the wrapping range ($76+$), the second node (with token 25) is responsible for the data range $1-25$, and so on %The node with the lowest token also accepts row keys less than the lowest token and more than the highest token 
\cite{CassandraPartitioning}.

\myFigureTiny{cassandra-ring-partitions}{Cassandra's ring for data partitioning \cite{CassandraPartitioning}}

%\myFigure{cassandra-vnodes}{Cassandra's ring for data partitioning}
% \emph{virtual nodes}
 
\subsection{Hadoop}

Hadoop is an open-source, distributed data processing framework inspired by Google's publications about MapReduce~\cite{Dean:2008:MSD:1327452.1327492} and the Google File System~\cite{Ghemawat:2003:GFS:945445.945450}. Originally developed at Yahoo!, Hadoop is now an Apache project~\cite{Hadoop}. Like Google's systems, Hadoop is designed to run on commodity hardware, i.e.\ server clusters built from commercial off-the-shelf products. Hadoop provides a distributed file system (HDFS) and a column family database (HBase). All software in the Hadoop framework is written in Java.

The MapReduce paradigm defines a parallel, asynchronous way of processing the data. As the name implies, MapReduce consists of two phases: the \emph{map} function processes each item of a list. The resulted list is then aggregated by the \emph{reduce} function.

Hadoop is often used for sorting, filtering and aggregating data sets. It is also used for fault-tolerant, distributed task execution.

A typical small Hadoop cluster consists of a single master node which is responsible for the coordination of the cluster and worker nodes which deal with the data processing. The MapReduce job is coordinated by the master's \emph{job tracker} and processed by the slave nodes' \emph{task tracker} modules (\figref{hadoop-architecture}).

\myFigureSmall{hadoop-architecture}{Hadoop's architecture \cite{HadoopMultinode}}

\subsubsection{HDFS}

The Hadoop Distributed File System (HDFS) is an open-source, distributed file system, inspired by the Google File System and written specifically for Hadoop~\cite{Hadoop}. Unlike other distributed file systems (e.g.\ Lustre~\cite{Lustre}), which require expensive hardware components, HDFS was designed to run on commodity hardware.

HDFS tightly integrates with Hadoop's architecture (\figref{hdfs}). The \emph{NameNode} is responsible for storing the metadata of the files and the location of the replicas. The data is stored by the \emph{DataNode}s.

\myFigure{hdfs}{HDFS' architecture}

\subsubsection{HBase}

HBase is an open-source, distributed column family database. It is developed as part of the Hadoop project and runs on top of HDFS. The tables in an HBase database can serve as the input and the output for MapReduce jobs run in Hadoop.

\subsection{Neo4j}
\label{subsec:neo4j}

Neo4j, developed by Neo Technology, is the most popular NoSQL graph database. Neo4j implements TinkerPop's Blueprints property graph data model along with Gremlin. It also provides Cypher, a declarative query language for graph pattern matching. 

Neo4j is one of the most mature NoSQL databases. It is well documented and provides ample tooling. However, it is scalability features are limited: instead of sharding, it only supports replication of data to create a highly available cluster. Of course, the scalability limitations are a hot topic in Neo4j's development. Neo4j's developers make serious efforts to improve Neo4j's scalability in an ongoing project called Rassilon~\cite{rassilon}.

Neo4j is capable of loading graphs from \graphml{}~\cite{GraphML} and Blueprints \graphson{}~\cite{BlueprintsGraphSON} formats (see \autoref{sec:property-graph-formats} for examples). Neo4j graphs can be visualized in Neoclipse, an Eclipse RCP application~\cite{Neoclipse}. %A part of a \tb{} (\autoref{sec:trainbenchmark}) instance model is shown on \figref{neoclipse-graph}.

\section{Graph technologies}

\subsection{Titan}
\label{subsec:titan}

Titan is an open-source, distributed, scalable graph database from Aurelius, the creators of the TinkerPop framework. Unlike Neo4j, Titan is not a standalone database. Instead, it builds on top of existing NoSQL database technologies and leverages Hadoop's MapReduce capabilities. Titan supports various storage backends, including Cassandra and HBase.

\subsubsection{Mapping and sharding}

To store the graph, Titan maps each vertex to a row of a column family (\figref{titan-cassandra-mapping}). The row stores the identifer and the properties of the vertex, along both the incoming and outgoing edges' identifiers, labels and properties.

Titan uses the storage backend's partitioner (e.g.\ Cassandra's RandomPartitioner) to shard the data. A more sophisticated partitioning system that will allow for partitioning based on the graph's static and dynamic properties (its domain and connectivity, respectively) is under implementation as of October 2013, but not yet available.

\myFigureSmall{titan-cassandra-mapping}{Titan graph vertex stored in Cassandra as a row}

\subsubsection{Deployment}

Titan can be deployed in different ways according to the needs of the application. For \iqd's prototype, we used Titan in \textit{remote server mode} (\figref{titan-modes-distributed}). In this setup, Titan runs in the same Java Virtual Machine as the application and communicates with the Cassandra cluster on a low-level protocol (e.g.\ Thrift).

\myFigure{titan-modes-distributed}{Using Titan with Cassandra in remote server mode}

\subsubsection{Faunus}
\label{subsubsec:faunus}

Although Titan was designed with scalability in mind, its query engine does not work in a parallel fashion. Also, it is unable to cope with queries resulting in millions of graph elements. To address this shortcoming, Aurelius developed a Hadoop-based graph analytics engine, Faunus.

Faunus has its own format called Faunus \graphson{}. The Faunus \graphson{} format is vertex-centric: each row represents a vertex of the graph. This way, Hadoop is able to efficiently split the input file and parallelize the load process. See \autoref{subsec:faunus-graphson} for an example.

It is important to note that Faunus always traverses the whole graph and does not use its indices. This makes it slow for retrieving nodes or edges by type (see our typical workload in \autoref{indexing}).

\subsection{4store}

4store is an open-source, distributed triplestore created by Garlik~\cite{4store}. Unlike the other tools discussed earlier, 4store is written in C. While 4store is primarily applied for semantic web projects, its maturity and scalability made it an appropriate storage backend for \iqd's prototype.

Similar to Titan's partitioning, 4store's sharding mechanism (called \emph{segmenting}) distributes the RDF resources evenly across the cluster. However, unlike Titan, 4store's data model is an RDF graph. Hence, 4store's input format is RDF/OWL.

\myFigureBig{4s-cluster}{4store's distributed architecture~\cite{harris20094store}}

\begin{tabl}{Overview of database technologies}{database-technologies}{ | l | l | l | m{2cm} | l | m{2cm} | }
\hline
\bf Technology & 
\bf Data model & 
\bf Sharding & 
\bf Distributed operation & 
\bf DML facility & 
\bf Identifier generation \tabularnewline \hline\hline
4store     & RDF            & Automatic & Manual                & SPARQL       & Manual                \\ \hline
Neo4j      & Property graph & Manual    & Manual                & Cypher       & Manual                \\ \hline
Titan      & Property graph & Automatic & Automatic             & Gremlin      & Automatic             \\ \hline
\end{tabl}

\autoref{tab:database-technologies} summarizes the relevant characteristics of the aforementioned database management systems. Accoding to these, Titan provides the most complete feature set. 4store and Neo4j lack important features like automatic identifier generation, which has to be implemented in the client application. Neo4j also misses automatic sharding, which seriously hinders its scalability potential. 

\section{Asynchronous messaging}

Most distributed, concurrent systems use a messaging framework or message queue service. Because of the nature of the Rete algorithm (\autoref{rete}), \iqd{}\ requires a distributed, asynchronous messaging framework.

\subsection{Akka}
\label{subsec:akka}

Akka is an open-source, fault-tolerant, distributed, asynchronous messaging framework developed by Typesafe \cite{Akka}.
Akka is implemented in Scala, a functional and object-oriented programming language which runs on the Java Virtual Machine. Akka provides language bindings for both Java and Scala.

%\myFigure{akka-actor-path}{Determining an actor's path in Akka}

Akka is based on the actor model \cite{Hewitt:1973:UMA:1624775.1624804} and provides built-in support for remoting. % citation?
Unlike traditional remoting solutions, e.g.\ Java RMI (Remote Method Invocation) and CORBA (Common Object Request Broker Architecture), the remote and local interface is the same for each actor. Actors have both a logical and a physical path (\figref{akka-remote-deployment}). This way, they can be transparently moved between machines on the network.

As of October 2013, the latest version (Akka 2.2) also features \textit{pluggable transport support} to use various transports to communicate with remote systems \cite{Akka}. For serializing the messages, Akka supports different frameworks, including Java's built-in serialization, Google Protobuf \cite{Protobuf} and Thrift \cite{Thrift}.

\myFigure{akka-remote-deployment}{Deploying a remote actor in Akka}

%\section{Google Guava libraries}
%\iqd{} relies heavily on Google Guava library's Collections framework~\cite{guava}. The Guava Collection is an extension to Java's Collection framework. We used both immutable collections and new type of collections (e.g.\ the \texttt{Multimap} interface and its implementations).

\section{Eclipse-based technologies}

Eclipse is a free, open-source software development environment and a platform for plug-in development. Members of the Eclipse Foundation include industry giants like IBM, Intel, Google and SAP.

\iqd{}'s single workstation predecessor, \eiq{} is built around Eclipse-based technologies. To reap the benefits of a mutual code base, we designed \iqd\ to use as much of \eiq's components as possible. In the following section, we introduce the Eclipse-based technologies most important for our work.

\subsection{EMF}
\label{subsec:EMF}

Eclipse comes with its own modeling technologies called EMF (Eclipse Modeling Framework). EMF provides a metamodel (Ecore) for designing applications and a code generation facility to produce the Java classes for the model.

\myFigure{ecore-metamodel}{The metamodel of Ecore}

\subsection{\eiq{}}
\label{subsec:eiq}

\eiq{} is developed by the Fault Tolerant Systems Research Group (FTSRG) in the Budapest University of Technology and Economics. \eiq{} is an open-source Eclipse project which provides incremental query evaluation on EMF models. The queries (graph patterns) are defined in \iq{} Pattern Language (IQPL), a domain-specific language implemented in Xtext and Xtend. \eiq{}'s architecture is shown on \figref{incquery-architecture}.

\myFigure{incquery-architecture}{\eiq{}'s architecture}

% Ez a 2.7-es rész kicsit kilóg színvonalban (lefelé) a többihez képest.
% 
% Egyértelműbben le kellene írni, hogy mi az Eclipse és az EMF-IncQuery szerepe:
% - Eclipse = tooling környezet
% - EMF-IncQuery = tooling bizonyos részei
% 
% Ami háttértechnológiaként nagyon fontos az Eclipse-ből, az a metamodeling + EMF (erről legalább 1 teljes oldal kellene, ábrával), és az IncQuery-t is sokkal részletesebben el kellene magyarázni.

