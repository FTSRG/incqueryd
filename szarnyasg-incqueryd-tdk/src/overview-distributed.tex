\section{Extensions for Distributed Scalability}

Developing a distributed, scalable, incremental pattern matcher introduces numerous challenges. In the following, we will cover the \iqd{}'s architecture and its main extensions to \eiq{}.

\pic{incqueryd-architecture}{\iqd{}'s architecture on a four-node cluster}

\subsection{\iqd{}'s Architecture}

The \iqd{} architecture in an example configuration is shown in \figref{incqueryd-architecture}. \iqd{}'s architecture consists of three layers: the storage layer, the middleware and the production network. 
The \emph{storage layer} is a distributed database which is responsible for persisting the model (\autoref{storage}). 
The client application communicates with the \emph{middleware} \textcircled{1}. The middleware provides a unified API for accessing the database \textcircled{2}. It also sends change notifications \textcircled{3} (\autoref{notifications}) to the production network and retrieves the query results from the production network \textcircled{4} . 
The \emph{production network} is implemented with a distributed Rete net which provides incremental query evaluation (\autoref{rete}).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Indexing and Initialization}
\label{indexing}

Indexing is a common technique for decreasing the execution time of database queries. In MDE, \emph{model indexing} is the key to high performance model queries. As MDE primarily uses a metamodeling infrastructure, all queries utilize some type attribute. In property graphs, the equivalents are node type properties and edge labels (see also \autoref{ecore-mapping}). Typical elementary model queries are the following:

\begin{itemize}
  \item Retrieving all node instances of a given type (e.g.\ get all nodes with the type \texttt{Person}).
  \item Retrieving all edges instances of a given label (e.g.\ get all edges with the label \texttt{child}).
  \item Retrieving a given node's all incoming and/or outgoing edges of a given type (e.g.\ get all outgoing \texttt{child} edges of a given node). 
  \item Reverse navigation: retrieving the node on the other end of an edge (e.g.\ the \texttt{child} relation is identical to the inverse of the \texttt{parent} relation). 
\end{itemize}

To process these queries efficiently, the \iqd{} middleware maintains type-instance indexes so that all instances of a given type (both edges and graph nodes) can be enumerated quickly. These indexers form the bottom layer of the Rete production network. During initialization, these indexers are filled from the database backend (\figref{incqueryd-architecture} \textcircled{2}). In order to reduce the initialization time, the underlying storage layer must be able to process these queries efficiently. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Distributed Storage Layer}
\label{storage}

For the storage layer, the most important issue from an incremental query evaluation perspective is that the indexers of the middleware should be filled as quickly as possible. This favors technologies where model sharding can be performed efficiently (i.e.\ with balanced shards in terms of type-instance relationships), and elementary queries 
can be executed efficiently.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Notification in Distributed Database Management Systems}

While relational databases usually provide \emph{trigger}s for generating notifications, most triplestores and graph databases lack this feature. Among our primary database backends, 4store provides no triggers at all. Titan and Neo4j incorporate Blueprints, which provides an \texttt{EventGraph} class capable of generating notification events, but the events are only propagated in a single JVM (Java Virtual Machine). Implementing distributed notifications would require us to extend the \texttt{EventGraph} class and use a messaging framework. This is subject to future work (see \autoref{sec:future-work}). 

Because the lack of support for distributed notifications, in \iqd{}'s current implementation, notifications are controlled by the middleware by providing a facade for all model manipulation operations (\figref{incqueryd-architecture} \textcircled{3}). The notification messages are propagated through the Rete network via the Akka messaging framework. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Graph-like Data Manipulation}

\iqd{}'s middleware exposes an API that provides methods to manipulate the graph. By allowing graph-like data manipulation we allow the user to focus on the domain-specific challenges, thus increasing her productivity. The middleware translates the user's operation and forwards it to the underlying data storage (e.g.\ SPARQL queries for 4store and Gremlin queries for Titan).

\subsubsection{Data Representation}

Conceptually, the architecture of \iqd{} allows the usage of a wide scale of model representation formats. Our prototype has been evaluated in the context of the \emph{property graph} and the \emph{RDF} data model, but other mainstream metamodeling and knowledge representation languages such as relational databases' SQL dumps and Ecore instance models~\autoref{ecore} could be supported, as long as they can be mapped to an efficient and distributed storage backend (e.g.\ triplestores, key-value stores or column-family databases).

To support different data models, we only have to supply the appropriate connector class to \iqd{}'s middleware. The current implementation supports 4store, Neo4j and Titan. % Ertelemszeruen Neo4j-t a mostani verzioba nem hoztam at 100%-ig 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Degrees of Freedom}
 
The Rete algorithm (\autoref{rete}) utilizes both indexing and caching to provide fast incremental query evaluation. \iqd{}'s horizontal scalability is supported by the distribution of the pattern matcher's Rete net. To enable this, the system must be able to allocate the Rete nodes to different hosts in a cloud computing infrastructure. 

The deployment and configuration of a distributed pattern matcher involves many degrees of freedom, and design decisions. The overall performance of the system is influenced by a number of factors.

\begin{itemize}
  \item For the storage layer, we may choose different database implementations due to the \iqd{}'s backend-agnostic nature. In this report, we used property graph databases (Neo4j, Titan) and triplestores (4store).
  \item We may use different database sharding strategies (e.g.\ random partitioners or more sophisticated sharding methods based on domain-specific knowledge).
  \item Using query optimization methods, we can derive \emph{Rete networks with different layouts} for the same query. The most efficient layout can be choosen based on both query and instance model characteristics, e.g.\ to keep the resource requirement of intermediate join operations to a minimum.
  \item We may choose different strategies to \emph{allocate the Rete nodes} in the distributed system. The optimization strategy may choose to optimize local resource usage, or to minimize the amount of remote network communication. Note that in theory, this is \emph{orthogonal} to the database's sharding strategy, i.e.\ these are two distinct level of distribution that do not directly depend upon each other. However, we expect that keeping the Rete network's type indexer nodes and the instances of the given type on the same server would improve the speed of the initialization and modification tasks significantly.
  \item We may implement \emph{dynamic adaptability} to changing conditions. For example, when the model size and thus query result size grows rapidly, the Rete network may require \emph{dynamic reallocation} or \emph{node sharding} due to local resource limitations.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Distributed Termination Protocol}

\iqd{}'s current termination protocol works by adding a stack to the message. The stack registers each Rete node the message passes through. After the message reaches the production node, the termination protocol starts. Based on the content of the stack, acknowledgement messages are propagated back on the network. When all relevant indexer nodes (where the original notification token(s) started from) receive the acknowledge messages, the termination protocol finishes.

\subsection{Workflow}
\label{iqd-workflow}

In the following part, we will describe the workflow behind the pattern matching process. Starting from a metamodel, an instance model and a graph pattern, we will cover the problem pieces that need to be solved for setting up an incremental, distributed pattern matcher. The workflow is shown on \figref{incqueryd-workflow}.
 
\pic{incqueryd-workflow}{The workflow of \iqd{}} 

By design, \iqd{}'s workflow's steps are similar to \eiq{}'s, discussed in \autoref{eiq-workflow}. However, due to the system's distributed nature, they are more difficult to design and implement.
In \iqd{}, deploying the Rete network \textcircled{2} requires the deployment of remote actors \autoref{subsec:akka} on the servers. Both the Rete indexers and the database are distributed across the cluster. Hence, loading the model and initializing the Rete net needs network communication \textcircled{3}. The Rete net works using Akka's remote messaging feature. The query results can be retrieved from the Rete net (this may also require network communication) \textcircled{4}. The database shards can only be accessed through the middleware, which is reponsible for sending notifications to the Rete net's appropriate indexers. After the notifications are processed and the termination algorithm finishes, the Rete net is in a consistent state \textcircled{5}. The results can be retieved by the client and it may modify the model an reevaluate the query again \textcircled{6}. 
