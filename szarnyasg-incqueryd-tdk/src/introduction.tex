\chapter{Introduction}
\label{chap:introduction}

% Based on our earlier publication , we present the context of this report. We formulate the problem and define the goals of our research.

\section{Context}
\label{context}

Nowadays, model-driven software engineering (MDE) plays an important role in the development processes of critical embedded systems\footnote{\autoref{context} and \autoref{problem-statement} are based on our earlier publication \cite{Izso:2013:IIG:2487766.2487772}. The new accomplishments of this report are detailed at the end of \autoref{summary}.}. Advanced modeling tools provide support for a wide range of development tasks such as requirements and traceability management, system modeling, early design validation, automated code generation, model-based testing and other validation and verification tasks. 

Models representing sensor data, reverse engineered software models (e.g.\ abstract syntax trees of existing source code) and geospatial models can contain well over $10^9$ modeling elements \cite{Scheidgen12}. The dramatic increase in complexity is also affecting critical embedded systems in recent years. Modeling toolchains are facing scalability challenges as the size of design models constantly increases, and automated tool features become more sophisticated.

\section{Problem Statement and Requirements}
\label{problem-statement}

Many scalability issues can be addressed by improving query performance. \emph{Incremental evaluation} of model queries aims to reduce query response time by limiting the impact of model modifications to query result calculation. Such algorithms work by either (i) building a cache of interim query results and keeping it up-to-date as models change (e.g.\ \eiq{}~\cite{models10}) or (ii) applying impact analysis techniques and re-evaluating queries only in contexts that are affected by a change (e.g.\ the Eclipse OCL Impact Analyzer~\cite{OCLIA}). This technique has been proven to improve performance dramatically in several scenarios (e.g.\ on-the-fly well-formedness validation or model synchronization), at the cost of increasing memory consumption. Unfortunately, this overhead is combined with the increase in model sizes due to in-memory representation (found in state-of-the-art frameworks such as EMF~\cite{EMF}).

% memory consumption is the most significant scalability limitation. The reason for this
A trivial solution would be to increase the memory. However, the Garbage Collector (GC) cannot handle heap sizes larger than 10~GB efficiently, thus introducing long pauses in the application~\cite{Azul}. Of course, this problem is well-known in the Java community. There are alternative Java Virtual Machines (JVMs) with specialized Garbage Collectors, like Azul Systems' JVM. However, the Azul JVM is a proprietary product and has specific hardware requirements. Also, this does not solve the scaling problem entirely -- the model size is still limited by the total amount memory in a single computer.

An alternative approach to tackling MDE scalability issues is to make use of advances in persistence technology. As the majority of model-based tools uses a graph-oriented data model, recent results of the NoSQL and Linked Data movement~\cite{neo4j,openvirtuoso,sesame} are straightforward candidates for adaptation to MDE purposes. Unfortunately, this idea poses difficult conceptual and technological challenges: (i) property graph databases lack strong metamodeling support and their query features are simplistic compared to MDE needs, and (ii) the underlying data representation format of semantic databases (RDF~\cite{website:rdf_standard}) has crucial conceptual and technological differences to traditional metamodeling languages such as Ecore~\cite{EMF}. Additionally, while there are initial efforts to overcome the mapping issues between the MDE and Linked Data worlds~\cite{hillairet2008bridging}, even the most sophisticated NoSQL storage technologies lack efficient and mature support for executing expressive queries \emph{incrementally}.

%Ez a két rész érdemi bővítésre szorul.
%Mik (tételesen) azok a kihívások, amelyekre a dolgozat megoldást kíván találni? Miért jelentősek / nehezek ezek (elméleti, gyakorlati szempontból)?
%Mi az IncQueryD mint megközelítés lényege? Hogyan fogja ez megoldani a fentebb részletezett kihívásokat?
%Legalább a következő oldal aljáig érjen a bevezető!

% miben haladja meg a state of the artot
% scalability
% open-source technologiak lekerdezeseinel gyorsabbak vagyunk
% This is a serious problem for MDE, where the queries are typically more complex than in traditional, transactional database management.
%\eiq{} is proven to be efficient for incremental query evaluation on small to medium-sized models (in the order of magnitude of $10^6$). However, model-driven engineering challenges often present large models, with $10^9$ or more elements \cite{Scheidgen12}.

\section{Objectives and Contributions}

We aimed to address the scalability challenge of MDE by adapting incremental graph search techniques from \eiq{} to the cloud infrastructure---instead of \emph{vertical scaling} (putting more resources to the same workstation), we decided to opt for \emph{horizontal scaling} (using multiple computers).

On the theoretical side, we adopted \eiq{}'s exiting incremental pattern matching algorithm. We extended the algorithm to work in a distributed environment and present a \emph{novel architecture}, which is capable of loading, transforming and incrementally querying models, while utilizing the \emph{total amount of memory} in the cluster. 

To build a scalable incremental query engine, we needed a distributed software stack. This included a distributed database management system and a messaging framework. We defined the evaluation criteria for these systems and evaluated them accordingly. Based on the architecture and the pattern matcher algorithm, we built a system prototype and compared its performance to existing tools.

We extended an existing \emph{benchmark environment} to evaluate the scalability characteristics of the system. We conducted benchmarks with different storage backends and query engines.

\section{Structure of the Report}
 
The report is structured as follows. 
\autoref{chap:background-technologies} introduces the background technologies and the motivation for building a distributed, incremental graph pattern matcher. \autoref{chap:overview} provides an overview of current a single-node incremental pattern macher, \eiq{}. 
\autoref{chap:evaluation} shows an initial performance evaluation in the context of on-the-fly well-formedness validation of software design models. 
\autoref{chap:related-work} discusses the related work. \autoref{chap:conclusions} concludes the report and presents our future plans. 

